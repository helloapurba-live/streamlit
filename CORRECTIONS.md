# CORRECTIONS AND KNOWN LIMITATIONS

This document details corrections made to the initial implementation and known limitations.

---

## ‚úÖ CRITICAL CORRECTIONS APPLIED

### 1. PyTorch Model Softmax Issue (FIXED)

**Problem**: The `FraudDetectionMLP.forward()` method incorrectly applied `F.softmax()` when using `CrossEntropyLoss`.

**Why This Is Wrong**:
- `nn.CrossEntropyLoss` expects raw logits (unnormalized scores)
- CrossEntropyLoss applies `log_softmax()` internally
- Applying softmax in forward() causes double softmax ‚Üí incorrect gradients and poor training

**Fix Applied**: Removed softmax from `forward()` method
```python
# BEFORE (INCORRECT):
def forward(self, x):
    x = self.fc4(x)
    return F.softmax(x, dim=-1)  # ‚ùå Wrong with CrossEntropyLoss

# AFTER (CORRECT):
def forward(self, x):
    x = self.fc4(x)
    return x  # ‚úÖ Return logits for CrossEntropyLoss
```

**File**: `src/ml/train_pytorch.py` (line 73)

**Reference**: PyTorch Documentation - https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html

---

### 2. Deprecated Optuna API (FIXED)

**Problem**: Used deprecated `trial.suggest_loguniform()` which is removed in Optuna 3.x

**Fix Applied**: Updated to modern API
```python
# BEFORE (DEPRECATED):
lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)  # ‚ùå Deprecated in Optuna 3.0+

# AFTER (CORRECT):
lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)  # ‚úÖ Optuna 3.x compatible
```

**File**: `src/ml/optuna_tune.py` (line 33)

**Reference**: Optuna 3.0.0 Release Notes - https://github.com/optuna/optuna/releases/tag/v3.0.0

---

### 3. Missing Python Package Structure (FIXED)

**Problem**: Missing `__init__.py` files would cause `ModuleNotFoundError` when importing across packages.

**Fix Applied**: Added `__init__.py` files to all package directories:
- `src/__init__.py`
- `src/backend/__init__.py`
- `src/frontend/__init__.py`
- `src/ml/__init__.py`
- `src/utils/__init__.py`

**Reference**: Python Packages Documentation - https://docs.python.org/3/tutorial/modules.html#packages

---

## ‚ö†Ô∏è KNOWN LIMITATIONS

### 1. Dummy Feature Values in Single Predictions

**Issue**: The `/predict_single` endpoint uses dummy values for behavioral features:

```python
# In prepare_features():
0.0,  # time_since_last_transaction (unknown)
transaction.amount,  # customer_avg_amount (using current as proxy)
0.0,  # customer_std_amount (unknown)
0.0,  # amount_deviation (unknown)
0.5,  # merchant_risk_score (neutral default)
1.0,  # distance_from_home (dummy)
```

**Impact**:
- Training-serving skew (model trained on real features, served with dummy features)
- Predictions may be less accurate than batch predictions
- Cannot capture customer behavioral patterns properly

**Mitigations**:
1. **Low-confidence flag**: Mark predictions with dummy features as "low confidence"
2. **Customer cache**: Implement customer feature cache/database
3. **On-the-fly computation**: Calculate features from transaction history in real-time

**Production Recommendation**: Build a customer feature service that maintains recent transaction statistics.

---

### 2. Streamlit Polling UI Blocking

**Issue**: The batch job polling uses `time.sleep(5)` in a `while` loop, which blocks the Streamlit UI.

**Location**: `src/frontend/app.py` (line 761)

**Impact**:
- UI freezes during polling period
- Cannot interact with dashboard while job is processing
- Not ideal UX for production

**Current Workaround**: The blocking is limited to 5-second intervals, and the UI updates between intervals.

**Production Recommendations**:
1. **Use st.rerun() with polling button**: User clicks "Refresh" button to check status
2. **JavaScript-based polling**: Implement custom JavaScript component for non-blocking polling
3. **WebSocket updates**: Use WebSocket connection for real-time updates
4. **Separate monitoring page**: Dedicated page that auto-refreshes every N seconds

**Example Better Pattern**:
```python
# Option 1: Manual refresh button
if st.button("üîÑ Refresh Status"):
    st.rerun()

# Option 2: Auto-refresh with st.experimental_rerun (if available)
import time
time.sleep(5)
st.experimental_rerun()
```

---

### 3. No Real LLM Integration

**Issue**: The `/agent_investigate` endpoint returns hardcoded mock responses, not real LLM analysis.

**Location**: `src/backend/app.py` (lines 764-816)

**Impact**: Investigation feature is demonstrative only.

**Production Recommendations**:
1. **Integrate local LLM**: Use llama.cpp, Ollama, or similar for local inference
2. **Use API services**: OpenAI, Anthropic, or other LLM APIs
3. **RAG pipeline**: Combine transaction history retrieval with LLM reasoning
4. **Prompt engineering**: Design effective prompts for fraud investigation

---

### 4. SQLite for Job Tracking

**Issue**: SQLite is used for job tracking, which has limitations:
- Single-writer constraint (concurrent writes will block)
- No distributed support
- Database locking issues on Windows

**Current Scope**: Acceptable for local development and small-scale deployment.

**Production Recommendations**:
- **PostgreSQL**: For multi-user production deployment
- **Redis**: For fast job queue and state management
- **RabbitMQ/Celery**: For robust distributed task queue

---

### 5. No Customer Feature Persistence

**Issue**: Customer behavioral features (avg_amount, std_amount, transaction history) are computed once during data generation but not persisted for inference.

**Impact**: Single predictions cannot access customer history.

**Production Recommendations**:
1. **Feature store**: Implement proper feature store (Feast, Tecton, or custom)
2. **Database**: Store customer aggregates in PostgreSQL/MongoDB
3. **Cache layer**: Redis cache for frequently accessed customer features
4. **Streaming**: Real-time feature computation with Kafka/Flink

---

### 6. Model Versioning

**Issue**: Basic model saving with joblib, no formal versioning or rollback capability.

**Current State**: Models saved with simple filenames (`sklearn_rf_model.pkl`)

**Production Recommendations**:
1. **MLflow Model Registry**: Use MLflow's registry with stages (staging, production)
2. **Version metadata**: Track model version, training date, performance metrics
3. **A/B testing**: Support multiple model versions in production
4. **Rollback capability**: Ability to revert to previous model version

---

## üìã VERIFICATION CHECKLIST

Before running the application, verify these fixes are in place:

### Critical Fixes
- [ ] `src/ml/train_pytorch.py`: forward() returns logits (no softmax)
- [ ] `src/ml/optuna_tune.py`: Uses `suggest_float(..., log=True)` not `suggest_loguniform`
- [ ] All `__init__.py` files created in package directories

### Expected Behavior After Fixes
- [ ] PyTorch model trains without numerical instability
- [ ] Optuna runs without deprecation warnings
- [ ] Imports work correctly (`from src.ml.train_pytorch import FraudDetectionMLP`)

### Known Limitations Acknowledged
- [ ] Single predictions use dummy features (lower accuracy expected)
- [ ] Streamlit UI freezes during batch job polling (5-second intervals)
- [ ] Investigation endpoint returns mock data (no real LLM)
- [ ] SQLite may have concurrency issues under load

---

## üîç TESTING AFTER CORRECTIONS

### Test 1: PyTorch Training
```powershell
python src\ml\train_pytorch.py
```

**Expected**: Training completes with ROC-AUC between 0.85-0.92, no numerical errors.

### Test 2: Optuna Tuning
```powershell
python src\ml\optuna_tune.py
```

**Expected**: Runs without deprecation warnings, completes 10 trials.

### Test 3: Package Imports
```powershell
python -c "from src.ml.train_pytorch import FraudDetectionMLP; print('‚úÖ Import successful')"
```

**Expected**: No ModuleNotFoundError.

### Test 4: Backend API
```powershell
# In separate terminal: uvicorn src.backend.app:app --reload
# Then:
curl -X POST http://localhost:8000/predict_single \
     -H "Content-Type: application/json" \
     -d '{"customer_id":"CUST_000123","amount":100.0,"merchant_category":"grocery",...}'
```

**Expected**: Returns prediction with fraud_probability (may be inaccurate due to dummy features).

---

## üìö ADDITIONAL RESOURCES

### For Production Deployment
1. **MLOps Best Practices**: "Designing Machine Learning Systems" by Chip Huyen
2. **Feature Stores**: Feast documentation - https://docs.feast.dev/
3. **Streamlit Advanced Patterns**: https://docs.streamlit.io/library/advanced-features
4. **FastAPI Production**: https://fastapi.tiangolo.com/deployment/
5. **Fraud Detection**: "Machine Learning for Fraud Detection" research papers

### Framework Documentation
- PyTorch: https://pytorch.org/docs/stable/index.html
- Skorch: https://skorch.readthedocs.io/
- Optuna: https://optuna.readthedocs.io/
- Streamlit: https://docs.streamlit.io/
- FastAPI: https://fastapi.tiangolo.com/

---

## üéØ SUMMARY

### What Was Fixed
‚úÖ PyTorch model softmax issue (critical training bug)
‚úÖ Optuna deprecated API (compatibility issue)
‚úÖ Python package structure (import errors)

### What Remains As Limitations
‚ö†Ô∏è Dummy features for single predictions (accuracy impact)
‚ö†Ô∏è Blocking UI during batch polling (UX issue)
‚ö†Ô∏è Mock LLM investigation (demo only)
‚ö†Ô∏è SQLite job tracking (scalability limit)

### Production Readiness
- **For Learning/Demo**: ‚úÖ Ready to use after corrections
- **For Small-Scale Internal Use**: ‚úÖ Acceptable with known limitations
- **For Production at Scale**: ‚ö†Ô∏è Requires additional hardening:
  - Real feature store
  - Non-blocking polling
  - Proper database (PostgreSQL)
  - Model versioning system
  - Authentication/authorization
  - Monitoring and alerting

---

**Last Updated**: 2025-01-20
**Corrections Applied**: 3 critical fixes
**Known Limitations**: 6 documented
